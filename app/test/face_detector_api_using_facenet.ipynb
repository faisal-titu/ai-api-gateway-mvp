{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from opensearchpy import OpenSearch\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image, ImageDraw\n",
    "import uuid\n",
    "from opensearchpy.helpers import bulk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/media/faisal/NewVolume/ResilientSage/FaceNet/dataset/images_faces\"\n",
    "FACE_CROP_DIR = \"/media/faisal/NewVolume/ResilientSage/faisal/Search/dada/facenet/dataset/cropped_faces\"\n",
    "os.makedirs(FACE_CROP_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MTCNN for face detection\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "face_detection_model = MTCNN(keep_all=True, min_face_size=30, device=device)\n",
    "embedding_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique face ID\n",
    "def generate_face_id(num_char=8):\n",
    "    return uuid.uuid4().hex[:num_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_plot_faces(image_path, crop_folder, margin=25):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        # Detect faces and their bounding boxes\n",
    "        boxes, probs = face_detection_model.detect(image)\n",
    "\n",
    "        if boxes is not None:\n",
    "            # Draw bounding boxes on the image\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            for i, (box, prob) in enumerate(zip(boxes, probs)):\n",
    "                if prob >= 0.98:  # Only process faces with high confidence\n",
    "                    # Enlarge the bounding box to add a margin around the face\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    x1 = max(0, x1 - margin)\n",
    "                    y1 = max(0, y1 - margin - 10)\n",
    "                    x2 = min(image.width, x2 + margin)\n",
    "                    y2 = min(image.height, y2 + margin)\n",
    "\n",
    "                    # Draw enlarged bounding box\n",
    "                    draw.rectangle([x1, y1, x2, y2])\n",
    "\n",
    "                    # Crop face using the enlarged bounding box\n",
    "                    cropped_face = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "                    # Save the cropped face with a unique face ID\n",
    "                    face_id = generate_face_id()\n",
    "                    cropped_face_path = os.path.join(crop_folder, f\"{face_id}.jpg\")\n",
    "                    cropped_face.save(cropped_face_path)\n",
    "\n",
    "                    # Image ID based on original image name\n",
    "                    image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "            #         # Plot the cropped face\n",
    "            #         plt.figure()\n",
    "            #         plt.imshow(cropped_face)\n",
    "            #         plt.title(f\"Face ID: {face_id}\")\n",
    "            #         plt.show()\n",
    "\n",
    "            #         # Print bounding box, face ID, and image ID\n",
    "            #         print(f\"Image ID: {image_id}, Face ID: {face_id}, Bounding Box: [{x1}, {y1}, {x2}, {y2}]\")\n",
    "\n",
    "            # # Plot the original image with bounding boxes\n",
    "            # plt.figure()\n",
    "            # plt.imshow(image)\n",
    "            # plt.title(f\"Detected Faces in {os.path.basename(image_path)}\")\n",
    "            # plt.show()\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_for_copy():\n",
    "    files = [f for f in os.scandir(DATASET_DIR) if f.is_file()]\n",
    "    print(f\"Found {len(files)} files in the dataset directory\")\n",
    "\n",
    "    for file in tqdm(files, desc=\"Processing images\"):\n",
    "        image_path = file.path\n",
    "        face_info = detect_and_plot_faces(image_path, FACE_CROP_DIR)\n",
    "\n",
    "        if face_info:\n",
    "            # This is where you could index or store the face_info (image_id, face_id, bounding_box)\n",
    "            print(face_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images_for_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbner of faces in the dataset\n",
    "files = [f for f in os.scandir(FACE_CROP_DIR) if f.is_file()]\n",
    "print(f\"Found {len(files)} faces in the dataset directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = [{'host': 'localhost', 'port': 9200}]\n",
    "\n",
    "def get_client():\n",
    "    client = OpenSearch(\n",
    "        hosts=host,\n",
    "        http_compress=True,\n",
    "        use_ssl=False,\n",
    "        verify_certs=False,\n",
    "        ssl_assert_hostname=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "    return client\n",
    "\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(client, index_name):\n",
    "    response = client.indices.create(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"settings\": {\n",
    "                \"index\": {\n",
    "                    \"knn\": True,\n",
    "                    \"knn.algo_param.ef_search\": 100\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"my_vector\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 512,\n",
    "                        \"method\": {\n",
    "                            \"name\": \"hnsw\",\n",
    "                            \"space_type\": \"cosinesimil\",\n",
    "                            \"engine\": \"lucene\",\n",
    "                            \"parameters\": {\n",
    "                                \"ef_construction\": 128,\n",
    "                                \"m\": 24\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"face_id\": {\"type\": \"keyword\"},\n",
    "                    \"image_id\": {\"type\": \"keyword\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bulk_indexing(client, actions):\n",
    "    response = bulk(client, actions)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_faces_and_generate_embeddings(face_crop_dir, index_name):\n",
    "    files = [f for f in os.scandir(face_crop_dir) if f.is_file()]\n",
    "    print(f\"Found {len(files)} cropped face images in the dataset directory\")\n",
    "\n",
    "    all_actions = []\n",
    "\n",
    "    for file in tqdm(files, desc=\"Generating embeddings\"):\n",
    "        image_path = file.path\n",
    "        try:\n",
    "            # Open the image\n",
    "            image = Image.open(image_path)\n",
    "            if image.mode != \"RGB\":\n",
    "                image = image.convert(\"RGB\")\n",
    "\n",
    "            # Preprocess the image for the embedding model\n",
    "            face_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "\n",
    "            # Generate face embedding\n",
    "            with torch.no_grad():\n",
    "                embedding = embedding_model(face_tensor).cpu().tolist()[0]\n",
    "\n",
    "            # Generate a unique face ID and use the image name as the image ID\n",
    "            face_id = generate_face_id()\n",
    "            image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "            # Create index action\n",
    "            action = {\n",
    "                \"_index\": index_name,\n",
    "                \"_id\": f\"{image_id}\",  # Unique ID for the image\n",
    "                \"_source\": {\n",
    "                    \"my_vector\": embedding,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"face_id\": face_id\n",
    "                }\n",
    "            }\n",
    "            all_actions.append(action)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    return all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    index_name = \"face_embeddings\"  # Define index name for OpenSearch\n",
    "    create_index(client, index_name)\n",
    "\n",
    "    # Process images and generate embeddings\n",
    "    actions = process_faces_and_generate_embeddings(FACE_CROP_DIR, index_name)\n",
    "\n",
    "    # Bulk index the embeddings in OpenSearch\n",
    "    if actions:\n",
    "        apply_bulk_indexing(client, actions)\n",
    "        print(f\"Indexed {len(actions)} face embeddings successfully.\")\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
